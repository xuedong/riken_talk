<!doctype html>
<html>
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<title>Bayesian Best-Arm Identification and Beyond</title>

	<link rel="stylesheet" href="dist/reset.css">
	<link rel="stylesheet" href="dist/reveal.css">
	<link rel="stylesheet" href="dist/theme/blood.css" id="theme">
	<link rel="stylesheet" href="css/custom.css">

	<!-- Theme used for syntax highlighted code -->
	<link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme">


</head>
<body>
	<div class="reveal">
		<div class="slides">
			<section class="title" data-background="images/tokyo.gif">
				<h4><span>Bayesian</span> <br>Best-Arm Identification <br>and Beyond</h4>
				<p class="authors">
					<medium><a href="https://xuedong.github.io/about/">Xuedong Shang</a></medium>
				</p>
				<p class="authors"><small>Inria Lille, SequeL Team</small>
				</p>
				<p>Thursday, December 17<sup>th</sup>, 2020</p>
				<footer>
					<img data-src="images/univ.png" height="50">
					<img data-src="images/inria.png" height="50">
					<img data-src="images/cnrs.png" height="50">
					<img data-src="images/centrale.png" height="50">
					<img data-src="images/cristal.svg" height="50">
				</footer>
			</section>


			<section>
				<section>
					<header><h3>Introduction</h3></header>
				</section>
 				<section>
					<header><h3>What</h3></header>
					<p text-align="center">Given a collection of <em>unknown</em> measurement distributions.</p>
					<div class="r-stack">
						<ol style="list-style-type: none;">
							<li class="fragment fade-in-then-out" data-fragment-index="0"><p>$$\nu_1: \mu_1, \nu_2: \mu_2, \cdots, \nu_K: \mu_K$$</p></li>
						</ol>
						<figure class="fragment fade-in-then-out" data-fragment-index="1">
							<video data-autoplay muted loop data-src="videos/multi_armed_bandit.webm" type="video/webm" height="400"></video>
							<figcaption>Illustration and animation by Jana Beck</figcaption>
						</figure>
					</div>
				</section>
				<section>
					<header><h3>Research questions</h3></header>
					<br>
					<ul>
						<li class="fragment" data-fragment-index="0">Regret <span class="green">minimization</span>: trade-off between exploration and exploitation</li>
						<li class="fragment" data-fragment-index="1">Best-arm <span class="red">identification</span>: pure exploration</li>
						<ol style="list-style-type: none;">
							<li class="fragment fade-in-then-out" data-fragment-index="2">
								<p>$$\mu^\star = \color{red}{\max}_i \mu_i$$</p>
								<p>$$I^\star = \color{red}{\operatorname{arg\,max}}_i \mu_i$$</p>
							</li>
						</ol>
					</ul>
				</section>
				<section>
					<header><h3>Motivation</h3></header>
					<div class="r-stack">
					<figure class="fragment fade-in-then-out" data-fragment-index="0">
						<img data-src="images/introduction/abc.png" width="100%">
						<figcaption>A/B/C testing</figcaption>
						<figcaption><p style="font-size: 40px">(Source: Julie Paci)</p></figcaption>
					</figure>
					<figure class="fragment fade-in-then-out" data-fragment-index="1">
						<img data-src="images/introduction/clinical_trials.png" width="100%">
						<figcaption>Design of clinical trials</figcaption>
						<figcaption>(Source: cbinsights.com)</figcaption>
					</figure>
					<figure class="fragment fade-in-then-out" data-fragment-index="2">
						<img data-src="images/introduction/hpo.png" width="100%">
						<figcaption>Hyper-parameter optimization</figcaption>
						<figcaption>(Source: Ramraj Chandradevan)</figcaption>
					</figure>
					</div>
				</section>
				<section>
					<header><h3>Outline</h3></header>
					<ul>
						<li class="fragment" data-fragment-index="0">Bayesian Best-Arm Identification
							<ol>
								<li class="fragment fade-in-then-semi-out" data-fragment-index="3"><a href="#/ttts">Theoretical insights</a></li>
								<li class="fragment fade-in-then-semi-out" data-fragment-index="4"><a href="#/t3c">Computational improvement</a></li>
							</ol>
						</li>
						<li class="fragment" data-fragment-index="1">Application to Hyper-parameter Optimization (HPO)
							<ol>
								<li class="fragment fade-in-then-semi-out" data-fragment-index="5"><a href="#/dttts">Best-arm identification for HPO</a></li>
								<li class="fragment fade-in-then-semi-out" data-fragment-index="6"><a href="#/fix">Adaptivity to $\mu^\star$</a></li>
							</ol>
						</li>
						<li class="fragment" data-fragment-index="2">Further discussion
							<ol>
								<li class="fragment" data-fragment-index="7"><a href="#/discussion">Extension to the linear case?</a></li>
							</ol>
						</li>
					</ul>
				</section>
			</section>


			<section>
				<section id="bai">
					<h2>Bayesian Best-Arm Identification</h2><br>
				</section>
				<section>
				<header><p>Formally, a BAI algorithm is composed of:</p></header>
				<ul>
					<li class="fragment" data-fragment-index="0">a sampling rule $\hat{I}$</li>
					<li class="fragment" data-fragment-index="1">a stopping rule $\tau$
						<ol>
							<li class="fragment fade-in-then-semi-out" data-fragment-index="2"><span class="green">fixed-budget</span>: stops when reach the budget $\tau = n$</li>
							<li class="fragment" data-fragment-index="3"><span class="red">fixed-confidence</span>: stops when the probability of outputting a wrong arm is less than $\delta$, minimize $\expectedvalue[\tau_\delta]$</li>
						</ol>
					</li>
					<li class="fragment" data-fragment-index="4">a decision rule
						<ol>
							<li class="fragment" data-fragment-index="5">outputs a guess $J_\tau$ of the best arm $I^\star$ when the algorithm stops</li>
						</ol>
					</li>
				</ul>
				</section>
				<section>
					<div class="r-stack">
						<p class="fragment fade-in-then-out" data-fragment-index="0">We are interested in <u>T</u>op-<u>T</u>wo <u>T</u>hompson <u>S</u>ampling <strong>(Russo, 2016)</strong></p>
						<!--pre><code class="fragment fade-in-then-out" data-fragment-index="1" data-trim data-noescape data-line-numbers>
input: beta
for n = 1, 2, ...
	for all i, theta_i ~ Pi_n
	let I1 = argmax_{i=0,...,m} theta_i
	if U ~ (Uniform([0,1])) > beta
		while I2 == I1
			for all i, theta_i' ~ Pi_n
			let I2 = argmax_{i=0,...,m} theta_i'
		let I1 = I2
	evaluate arm I1
	update Pi_n
						</code></pre-->
						<figure class="fragment fade-in-then-out" data-fragment-index="1">
							<img data-src="images/ttts/ttts1.png" width="100%">
						</figure>
					</div>
				</section>
				<section>
					<header><h3>Why?</h3></header>
					<ul>
						<li class="fragment" data-fragment-index="0">Beyond fixed-budget and fixed-confidence: anytime BAI framework <strong>(Jun and Nowak, 2016)</strong></li>
						<li class="fragment" data-fragment-index="1">A Bayesian competitor for BAI as Thompson sampling to <span class="green">UCB</span> for regret minimizing?
							<ol>
								<li class="fragment" data-fragment-index="2">It's often easier to sample from the fitted model than compute complicated optimistic estimates</li>
								<li class="fragment" data-fragment-index="3">Strong practical performance?</li>
							</ol>
						</li>
					</ul>
				</section>
				<section>
					<header><p>What we know about TTTS... (Posterior convergence)</p></header>
					<div class="r-stack">
					<ul>
						<li class="fragment fade-in-then-out" data-fragment-index="1">Assumptions</li>
						<ol>
							<li class="fragment fade-in-then-out" data-fragment-index="1">Measurement distributions are in the canonical one dimensional exponential family</li>
							<li class="fragment fade-in-then-out" data-fragment-index="1">The parameter space is a bounded open hyper-rectangle</li>
							<li class="fragment fade-in-then-out" data-fragment-index="1">The prior density is uniformly bounded</li>
							<li class="fragment fade-in-then-out" data-fragment-index="1">The log-partition function has bounded first derivative</li>
						</ol>
					</ul>
					<p class="theorem fragment" data-fragment-index="2"><strong>Theorem (Russo, 2016)</strong>
							Under TTTS and under the previous boundedness assumptions, it holds a.s.
    					\[
        				\lim_{n\rightarrow{\infty}} -\frac{1}{n}\log(1-\alpha_{n,I^\star}) = \color{red}{\Gamma_{\beta}^\star},
    					\]

    					where
    					\begin{equation*}
        				\quad \alpha_{n,i} \triangleq \Pi_{n}(\theta_i > \max_{j\neq i}\theta_j).
    					\end{equation*}
					</p>
					</div>
				</section>
				<section>
					<header><p>What we know about TTTS... (Complexity)</p></header>
					<div class="r-stack">
					<p class="theorem fragment fade-in-then-out" data-fragment-index="0"><strong>Definition</strong>
						Let $\Sigma_K = \{\omega : \sum_{k=1}^K \omega_k = 1, \omega_k \geq 0\}$ and define for all $i\neq I^\star$
						\[
    					C_i(\omega,\omega') \triangleq \min_{x\in\mathcal{I}} \omega d(\mu_{I^\star};x) + \omega' d(\mu_i;x),
						\]
						where $d(\mu,\mu')$ is the KL-divergence. We define
						\begin{eqnarray*}
    					\Gamma_{\beta}^\star \triangleq \max_{\substack{\omega \in \Sigma_K\\\omega_{I^\star}=\beta}}\min_{i\neq I^\star} C_i(\omega_{I^\star},\omega_i).\label{def:GammaBeta}
						\end{eqnarray*}
					</p>
					<p class="fragment" data-fragment-index="1"><span class="red">In particular, for Gaussian bandits...</span>
						\[
    					\Gamma_{\beta}^\star = \max_{\omega:\omega_{I^\star}=\beta}\min_{i\neq I^\star} \frac{(\mu_{I^\star}-\mu_i)^2}{2\sigma^2(1/\omega_i+1/\beta)}.
						\]
					</p>
					</div>
				</section>
				<section>
					<header><p>What we want to know about TTTS...</p></header>
					<ul>
						<li class="fragment" data-fragment-index="0">Can we 'relax' the aforementioned assumptions?</li>
						<li class="fragment" data-fragment-index="1">What can we say about the sample complexity in the fixed-confidence setting?</li>
						<li class="theorem fragment" data-fragment-index="2"><strong>Lower bound</strong>
							Under any $\delta$-correct strategy satisfying $T_{n,I^\star}/n \rightarrow \beta$,
    					\[\liminf_{\delta \rightarrow 0}\frac{\expectedvalue[\tau_\delta]}{\ln(1/\delta)} \geq \frac{1}{\Gamma^\star_\beta}.\]
						</li>
						<li class="fragment fade-in-then-semi-out" data-fragment-index="3">Can we have finite-time guarantees?</li>
					</ul>
					<p class="fragment fade-in-then-semi-out" data-fragment-index="4"></p>
				</section>
				<section id="ttts">
					<h2>Bayesian Best-Arm Identification</h2><br>
					<h4><ol><li>Theoretical insights</li></ol></h4>
					<br>
				</section>
				<section style="font-size: 75%">
					<header><h3>Main results</h3></header>
					<p>Posterior convergence</p>
					<p class="theorem fragment" data-fragment-index="0"><strong>Theorem 1 (Shang et al., 2020)</strong>
						Under TTTS, for Gaussian bandits with Gaussian priors, it holds a.s.
    				\[
        			\lim_{n\rightarrow{\infty}} -\frac{1}{n}\log(1-\alpha_{n,I^\star}) = \color{red}{\Gamma_{\beta}^\star}.
    				\]
					</p>
					<p class="theorem fragment fade-in-then-semi-out" data-fragment-index="1"><strong>Theorem 2 (Shang et al., 2020)</strong>
						Under TTTS, for Bernoulli bandits and uniform priors, it holds a.s.
						\[
							\lim_{n\rightarrow{\infty}} -\frac{1}{n}\log(1-\alpha_{n,I^\star}) = \color{red}{\Gamma_{\beta}^\star}.
						\]
					</p>
				</section>
				<section style="font-size: 75%">
					<header><h3>Main results</h3></header>
					<p>Sample complexity</p>
					<p class="theorem fragment" data-fragment-index="0"><strong>Theorem 3 (Shang et al., 2020)</strong>
						The TTTS sampling rule coupled with the Chernoff stopping rule form a $\delta$-correct BAI strategy. If all arm means are distinct,
    				\[
        			\limsup_{\delta\rightarrow{0}} \frac{\expectedvalue[\tau_{\delta}]}{\log(1/\delta)} \leq \frac{1}{\color{red}{\Gamma_{\beta}^\star}}.
    				\]
					</p>
					<p class="theorem fragment" data-fragment-index="1">Recall (Lower bound):
        		\[\liminf_{\delta \rightarrow 0}\frac{\expectedvalue[\tau_\delta]}{\ln(1/\delta)} \geq \frac{1}{\color{red}{\Gamma^\star_\beta}}.\]
					</p>
				</section>
				<section style="font-size: 75%">
					<header><h3>Proof sketch</h3></header>
					<p>$\delta$-correctness</p>
					<p class="theorem fragment" data-fragment-index="0">Stopping rule:
						\begin{equation}
    					\tau_\delta^{\text{Ch.}} ≜ \inf \left\lbrace n \in \mathbb{N} : \max_{i \in \mathcal{A}} \min_{j \in \mathcal{A} \setminus \{i\} } \color{lightskyblue}{W_{n}(i,j)} > d_{n,\delta} \right\rbrace.
						\end{equation}
					</p>
					<div class="r-stack">
					<p class="theorem fragment fade-in-then-out" data-fragment-index="1"><strong>Transportation cost</strong>:
						$\mu_{n,i,j} ≜ (T_{n,i}\mu_{n,i} +T_{n,j}\mu_{n,j})/(T_{n,i}+T_{n,j})$, then we define
						\begin{equation}\label{def:Transportation}
							\color{lightskyblue}{W_n(i,j)} ≜
							\left\{ \begin{array}{ll}
							0 & \operatorname{if} \mu_{n,j} \geq \mu_{n,i},\\
							W_{n,i,j}+W_{n,j,i} & \operatorname{otherwise},
							\end{array}\right.
						\end{equation}
						where $W_{n,i,j} ≜ T_{n,i} d\left(\mu_{n,i},\mu_{n,i,j}\right)$ for any $i,j$.
					</p>
					<p class="theorem fragment fade-in-then-out" data-fragment-index="2"><span class="red">In particular, for Gaussian bandits</span>:
						\[
							\color{lightskyblue}{W_n(i,j)} = \dfrac{(\mu_{n,i}-\mu_{n,j})^2}{2\sigma^2(1/T_{n,i}+1/T_{n,j})}\mathbb{1}\{\mu_{n,j}<\mu_{n,i}\}.
						\]
					</p>
					<p class="theorem fragment fade-in-then-out" data-fragment-index="3"><strong>Theorem (Shang et al., 2020)</strong>
						The TTTS sampling rule coupled with the Chernoff stopping rule with a threshold $d_{n,\delta} \simeq \log(1/\delta) + c\log(\log(n))$ and the recommendation rule $J_t = \operatorname{arg\,max}_i \mu_{n,i}$, form a $\delta$-correct BAI strategy.
					</p>
					<p class="theorem fragment fade-in-then-semi-out" data-fragment-index="4">Bayesian stopping rule:
						\[\tau_{\delta} ≜ \inf \left\{ n\in\mathbb{N}:\max_{i\in\mathcal{A}} \color{limegreen}{a_{n,i}} \geq c_{n,\delta} \right\}\,.\]
					</p>
					<p class="fragment" data-fragment-index="5"></p>
					</div>
				</section>
				<section style="font-size: 75%">
					<header><h3>Proof sketch</h3></header>
					<p>Sufficient condition for $\beta$-optimality</p>
					<p class="theorem fragment" data-fragment-index="0"><strong>Lemma (Shang et al. 2020)</strong>
						Let $\delta,\beta\in (0,1)$. For any sampling rule which satisfies $\expectedvalue[\color{lightskyblue}{T_{\beta}^\epsilon}] < \infty$ for all $\epsilon > 0$, we have
	    			\[
	        		\limsup_{\delta\rightarrow{0}} \frac{\expectedvalue[\tau_{\delta}]}{\log(1/\delta)} \leq \frac{1}{\Gamma_{\beta}^\star},
	    			\]
	    			if the sampling rule is coupled with the Chernoff stopping rule.
					</p>
					<p class="fragment" data-fragment-index="1">$\color{lightskyblue}{T_{\beta}^\epsilon} ≜ \inf \left\{ N\in\mathbb{N}: \max_{i\in\mathcal{A}} \vert T_{n,i}/n-\omega_i^\beta \vert \leq \epsilon, \forall n \geq N \right\}$.</p>
				</section>
				<section>
					<header><h3>Proof sketch</h3></header>
					<p>Core theorem</p>
					<p class="theorem fragment" data-fragment-index="0"><strong>Theorem (Shang et al. 2020)</strong>
						Under TTTS, $\expectedvalue[\color{lightskyblue}{T_{\beta}^\epsilon}] < +\infty$.
					</p>
					<p class="fragment" data-fragment-index="1">The proof is inspired by <strong>Qin et al. (2017)</strong>, but major technical novelties are introduced. In particular, our proof is much more intricate due to the randomized nature of the two candidate arms...</p>
				</section>
			</section>

			<section>
				<section id="t3c">
					<h2>Bayesian Best-Arm Identification</h2><br>
					<h4><ol start="2"><li>Computational improvement</li></ol></h4>
					<br>
				</section>
				<section>
					<p>TTTS</p>
					<figure class="fragment" data-fragment-index="0">
						<img data-src="images/ttts/ttts2.png" width="100%">
					</figure>
				</section>
				<section>
					<p>T3C (Top-Two Transportation Cost)</p>
					<figure class="fragment" data-fragment-index="0">
						<img data-src="images/ttts/t3c.png" width="100%">
					</figure>
				</section>
				<section>
					<header><h3>Main results</h3></header>
					<p>Sample complexity</p>
					<p class="theorem fragment" data-fragment-index="0"><strong>Theorem (Shang et al. 2020)</strong>
						The T3C sampling rule coupled with the Chernoff stopping rule form a $\delta$-correct BAI strategy. If all arm means are distinct,
						\[
							\limsup_{\delta\rightarrow{0}} \frac{\expectedvalue[\tau_{\delta}]}{\log(1/\delta)} \leq \frac{1}{\color{red}{\Gamma_{\beta}^\star}}.
						\]
					</p>
				</section>
				<section>
					<header><h3>Illustrations</h3></header>
					<p>Time consumption</p>
					<table>
						<thead>
							<tr>
								<th>Sampling rule</th>
								<th>T3C</th>
								<th>TTTS</th>
								<th>Uniform</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<td>Exec. time (s)</td>
								<td><span class="fragment highlight-blue" data-fragment-index="0">$1.6 \times 10^{-5}$</span></td>
								<td>$2.3 \times 10^{-4}$</td>
								<td><span class="fragment highlight-green" data-fragment-index="0">$6.0 \times 10^{-6}$</span></td>
							</tr>
						</tbody>
					</table>
				</section>
				<section>
					<header><h3>Illustrations</h3></header>
					<p>Average stopping time (Bernoulli)</p>
					<figure class="fragment" data-fragment-index="0">
						<img data-src="images/ttts/bernoulli1.png" width="49%">
						<img data-src="images/ttts/bernoulli2.png" width="49%">
					</figure>
				</section>
				<section>
					<header><h3>Illustrations</h3></header>
					<p>Average stopping time (Gaussian)</p>
					<figure class="fragment" data-fragment-index="0">
						<img data-src="images/ttts/gaussian1.png" width="49%">
						<img data-src="images/ttts/gaussian2.png" width="49%">
					</figure>
				</section>
			</section>

			<section>
				<section id="dttts">
					<h2>Application to Hyper-paramter Optimization</h2><br>
					<h4><ol><li>A Dynamic Algorithm</li></ol></h4>
					<br>
				</section>
				<section>
					<header><h3>Problem formulation</h3></header>
					<p style="text-align: left" class="fragment" data-fragment-index="0">We tackle <span class="red">hyper-parameter tuning</span> for <em>supervised learning</em> tasks:</p>
					<ul>
						<li class="fragment" data-fragment-index="1">global optimisation task: $\min\{f(\lambda):\lambda\in\Omega\}$</li>
						<li class="fragment" data-fragment-index="2">$f(\lambda) \triangleq \mathbb{E}\left[\ell\left(Y,\hat g_{\lambda}^{\,(n)}(X)\right) \right]$ measures the generalization power</li>
					</ul>
				</section>
				<section>
					<header><h3>How? - BAI</h3></header>
					<p style="text-align: left" class="fragment" data-fragment-index="0">We see the problem as BAI in a <em>stochastic infinitely-armed bandit</em>: arm means are drawn from some <em>reservoir distribution $\nu_0$</em></p>
					<div class="r-stack">
					<figure class="fragment fade-in-then-out" data-fragment-index="1">
						<img data-src="images/dttts/reservoir.jpg" width="100%">
					</figure>
					<ul style="text-align: left" class="fragment" data-fragment-index="2"><span class="green">In each round</span>:
						<li> (optional) query a new arm from $\nu_0$</li>
    				<li> sample an arm that was previously queried</li>
					</ul>
					</div>
					<p style="text-align: left" class="fragment" data-fragment-index="3"><span class="red">Goal</span>: output an arm with mean close to $\mu^\star$</span></p>
				</section>
				<section>
					<header><h3>How? - DTTTS</h3></header>
					<p><u>D</u>ynamic <u>T</u>op-<u>T</u>wo <u>T</u>hompson <u>S</u>ampling</p>
					<div class="r-stack">
					<ul style="text-align: left" class="fragment fade-in-then-out" data-fragment-index="0"><span class="green">In this talk...</span>
						<li> Beta-Bernoulli Bayesian bandit model</li>
    				<li> a uniform prior over the mean of new arms</li>
					</ul>
					<figure class="fragment fade-in-then-out" data-fragment-index="1">
						<img data-src="images/dttts/ttts.png" width="75%">
					</figure>
					<figure class="fragment fade-in-then-out" data-fragment-index="2">
						<img data-src="images/dttts/dttts.png" width="75%">
					</figure>
					</div>
				</section>
			</section>
		</div>
	</div>

	<script src="dist/reveal.js"></script>
	<script src="plugin/notes/notes.js"></script>
	<script src="plugin/search/search.js"></script>
	<script src="plugin/highlight/highlight.js"></script>
	<script src="plugin/math/math.js"></script>
	<script src="plugin/zoom/zoom.js"></script>
	<script async defer src="https://buttons.github.io/buttons.js"></script>
	<script>
		// More info about initialization & config:
		// - https://revealjs.com/initialization/
		// - https://revealjs.com/config/
		Reveal.initialize({
			hash: true,
			slideNumber: true,
			math: {
				mathjax: 'https://cdn.jsdelivr.net/gh/mathjax/mathjax@2.7.8/MathJax.js',
				config: 'TeX-AMS_HTML-full',
		      // pass other options into `MathJax.Hub.Config()`
		      TeX: { Macros: {
		      	Real: "{\\mathbb{R}}",
		      	cC: "{\\mathcal{C}}",
		      	expectedvalue: "\\mathop{\\mathbb{E}}",
		      }}
		  },
			// Learn about plugins: https://revealjs.com/plugins/
			plugins: [ RevealSearch, RevealHighlight, RevealNotes, RevealMath, RevealZoom ]
		});
	</script>
</body>
</html>
